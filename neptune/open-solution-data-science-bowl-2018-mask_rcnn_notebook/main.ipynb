{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/input/Mask_RCNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import imageio\n",
    "import skimage\n",
    "from config import Config\n",
    "from skimage.morphology import label\n",
    "from skimage.feature import canny\n",
    "from skimage import exposure\n",
    "from keras.callbacks import Callback\n",
    "from skimage.morphology import binary_closing, binary_opening, disk, binary_dilation\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "from sklearn.externals import joblib\n",
    "from skimage.transform import PiecewiseAffineTransform, warp\n",
    "from skimage.morphology import watershed\n",
    "from skimage.filters import sobel\n",
    "\n",
    "import utils\n",
    "import model as modellib\n",
    "import visualize\n",
    "from model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(127)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the mask_rcnn trained on COCO dataset to initialize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define the monitor that will help keep track on the training process.\n",
    "With this you will be able to see your charts in the `charts` tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(Callback):  \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.batch_id = 0\n",
    "        self.epoch_id = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.batch_id += 1\n",
    "        ctx.channel_send('loss', x=self.batch_id, y=float(logs.get('loss')))\n",
    "        ctx.channel_send('rpn_class_loss', x=self.batch_id, y=float(logs.get('rpn_class_loss')))\n",
    "        ctx.channel_send('rpn_bbox_loss', x=self.batch_id, y=float(logs.get('rpn_bbox_loss')))\n",
    "        ctx.channel_send('mrcnn_class_loss', x=self.batch_id, y=float(logs.get('mrcnn_class_loss')))\n",
    "        ctx.channel_send('mrcnn_bbox_loss', x=self.batch_id, y=float(logs.get('mrcnn_bbox_loss')))\n",
    "        ctx.channel_send('mrcnn_mask_loss', x=self.batch_id, y=float(logs.get('mrcnn_mask_loss')))\n",
    "    \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.epoch_id += 1\n",
    "        ctx.channel_send('val_loss', x=self.epoch_id, y=float(logs.get('val_loss')))\n",
    "        ctx.channel_send('val_rpn_class_loss', x=self.epoch_id, y=float(logs.get('val_rpn_class_loss')))\n",
    "        ctx.channel_send('val_rpn_bbox_loss', x=self.epoch_id, y=float(logs.get('val_rpn_bbox_loss')))\n",
    "        ctx.channel_send('val_mrcnn_class_loss', x=self.epoch_id, y=float(logs.get('val_mrcnn_class_loss')))\n",
    "        ctx.channel_send('val_mrcnn_bbox_loss', x=self.epoch_id, y=float(logs.get('val_mrcnn_bbox_loss')))\n",
    "        ctx.channel_send('val_mrcnn_mask_loss', x=self.epoch_id, y=float(logs.get('val_mrcnn_mask_loss')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will load the metadata and divide them in train and valid splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_split(meta, validation_size, valid_category_ids=None):\n",
    "    meta_train = meta[meta['is_train'] == 1]\n",
    "    meta_train_split, meta_valid_split = split_on_column(meta_train,\n",
    "                                                         column='vgg_features_clusters',\n",
    "                                                         test_size=validation_size,\n",
    "                                                         random_state=1234,\n",
    "                                                         valid_category_ids=valid_category_ids\n",
    "                                                         )\n",
    "    return meta_train_split, meta_valid_split\n",
    "\n",
    "\n",
    "def split_on_column(meta, column, test_size, random_state=1, valid_category_ids=None):\n",
    "    if valid_category_ids is None:\n",
    "        categories = meta[column].unique()\n",
    "        np.random.seed(random_state)\n",
    "        valid_category_ids = np.random.choice(categories,\n",
    "                                              int(test_size * len(categories)))\n",
    "    valid = meta[meta[column].isin(valid_category_ids)].sample(frac=1, random_state=random_state)\n",
    "    train = meta[~(meta[column].isin(valid_category_ids))].sample(frac=1, random_state=random_state)\n",
    "    return train, valid\n",
    "\n",
    "meta = pd.read_csv('/public/dsb_2018_data/stage1_metadata.csv')\n",
    "\n",
    "meta_ts = meta[meta['is_train']==0]\n",
    "meta_train, meta_valid = train_valid_split( meta[meta['is_train']==1],0.2,[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Mask-RCNN configuration\n",
    "We will now define parameters for our mask-rcnn. \n",
    "Tweak them to get better results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DsbConfig(Config):\n",
    "\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"dsb\"\n",
    "      \n",
    "    LEARNING_RATE = 1e-2\n",
    "    \n",
    "    # If enabled, resizes instance masks to a smaller size to reduce\n",
    "    # memory load. Recommended when using high-resolution image\n",
    "    USE_MINI_MASK = True\n",
    "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
    "    \n",
    "    # Train on 1 GPU and 8 images per GPU. Batch size is GPUs * images/GPU.\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 2\n",
    "    # Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch.\n",
    "    # typically be equal to the number of samples of your dataset divided by the batch size\n",
    "    STEPS_PER_EPOCH = 300\n",
    "    VALIDATION_STEPS = 70\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # background + nucleis\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    IMAGE_PADDING = True  # currently, the False option is not supported\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels, maybe add a 256?\n",
    "    # The strides of each layer of the FPN Pyramid. These values\n",
    "    # are based on a Resnet101 backbone.\n",
    "    BACKBONE_STRIDES = [4, 8, 16, 32, 64]\n",
    "    # How many anchors per image to use for RPN training\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 320 #300\n",
    "    \n",
    "    # ROIs kept after non-maximum supression (training and inference)\n",
    "    POST_NMS_ROIS_TRAINING = 2000\n",
    "    POST_NMS_ROIS_INFERENCE = 2000\n",
    "    POOL_SIZE = 7\n",
    "    MASK_POOL_SIZE = 14\n",
    "    MASK_SHAPE = [28, 28]\n",
    "    TRAIN_ROIS_PER_IMAGE = 512\n",
    "    RPN_NMS_THRESHOLD = 0.7\n",
    "    MAX_GT_INSTANCES = 256\n",
    "    DETECTION_MAX_INSTANCES = 400 \n",
    "    # Minimum probability value to accept a detected instance\n",
    "    # ROIs below this threshold are skipped\n",
    "    DETECTION_MIN_CONFIDENCE = 0.7 # may be smaller?\n",
    "    # Non-maximum suppression threshold for detection\n",
    "    DETECTION_NMS_THRESHOLD = 0.3 # 0.3\n",
    "    \n",
    "    \n",
    "    MEAN_PIXEL = np.array([0.,0.,0.])\n",
    "    \n",
    "    # Weight decay regularization\n",
    "    WEIGHT_DECAY = 0.0001\n",
    "    \n",
    "config = DsbConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(DsbConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    # MEAN_PIXEL = np.array([56.02288505, 54.02376286, 54.26675248])\n",
    "inference_config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset definition\n",
    "\n",
    "We need to define our datasets for the data science bowl competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DsbDataset(utils.Dataset):\n",
    "\n",
    "    def load_dataset(self, ids, train_mode=True):\n",
    "        self.add_class(\"dsb\", 1, \"nuclei\")\n",
    "        if train_mode:\n",
    "            directory = dsb_dir\n",
    "        else:\n",
    "            directory = test_dir\n",
    "        for i, id in enumerate(ids):\n",
    "            image_dir = os.path.join(directory, id)\n",
    "            self.add_image(\"dsb\", image_id=i, path=image_dir)\n",
    "            \n",
    "\n",
    "    def load_image(self, image_id, non_zero=None):\n",
    "        info = self.image_info[image_id]\n",
    "        path = info['path']\n",
    "        image_name = os.listdir(os.path.join(path, 'images'))\n",
    "        image_path = os.path.join(path, 'images', image_name[0])\n",
    "        image = imageio.imread(image_path)\n",
    "        if image.shape[2] != 3:\n",
    "            image = image[:,:,:3]\n",
    "        image = self.preprocess(image)\n",
    "        image = image.astype('float32')\n",
    "        return image\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"shapes\":\n",
    "            return info[\"shapes\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        path = info['path']\n",
    "        mask_dir = os.path.join(path, 'masks')\n",
    "        mask_names = os.listdir(mask_dir)\n",
    "        count = len(mask_names)\n",
    "        mask = []\n",
    "        for i, el in enumerate(mask_names):\n",
    "            msk_path = os.path.join(mask_dir, el)\n",
    "            msk = imageio.imread(msk_path)\n",
    "            if np.sum(msk) == 0:\n",
    "                print('invalid mask')\n",
    "                continue\n",
    "            msk = msk.astype('float32')/255.\n",
    "            mask.append(msk)\n",
    "        mask = np.asarray(mask)\n",
    "        mask[mask > 0.] = 1.\n",
    "        mask = np.transpose(mask, (1,2,0))\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        count = mask.shape[2]\n",
    "        for i in range(count-2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        class_ids = [self.class_names.index('nuclei') for s in range(count)]\n",
    "        class_ids = np.asarray(class_ids)\n",
    "        return mask, class_ids.astype(np.int32)\n",
    "    \n",
    "    def preprocess(self, img):\n",
    "        gray = skimage.color.rgb2gray(img.astype('uint8'))\n",
    "        img = skimage.color.gray2rgb(gray)\n",
    "        img *= 255.\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsb_dir = '/public/dsb_2018_data/stage1_train'\n",
    "train_ids = meta_train.ImageId.values\n",
    "val_ids = meta_valid.ImageId.values\n",
    "test_dir = '/public/dsb_2018_data/stage1_test'\n",
    "test_ids = os.listdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = DsbDataset()\n",
    "dataset_train.load_dataset(train_ids)\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = DsbDataset()\n",
    "dataset_val.load_dataset(val_ids)\n",
    "dataset_val.prepare()\n",
    "\n",
    "# Test dataset\n",
    "dataset_test = DsbDataset()\n",
    "dataset_test.load_dataset(test_ids, train_mode=False)\n",
    "dataset_test.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "OK! \n",
    "\n",
    "I think we are ready to do some training!\n",
    "We will instantiate the model and initialize it with COCO weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last()[1], by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train and investigate the learning curves for all the mask-rcnn losses in the `charts` and `channels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(dataset_train, dataset_val, \n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=10, \n",
    "                layers=\"all\", clbcks=[LossHistory()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "I think we are ready to see how our model does on the validation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()[1]\n",
    "\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission\n",
    "It is looking good on the validation.\n",
    "Let's see how will it do on the public LB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_predictions = []\n",
    "for test_id in dataset_test.image_ids:\n",
    "    test_image1 = dataset_test.load_image(test_id, 0)\n",
    "    pred = model.detect([test_image1], verbose=0)\n",
    "    pred = pred[0]\n",
    "    sc = pred['scores']\n",
    "    pred = pred['masks']\n",
    "    raw_predictions.append((pred, sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encoding(x):\n",
    "    '''\n",
    "    x: numpy array of shape (height, width), 1 - mask, 0 - background\n",
    "    Returns run length as list\n",
    "    '''\n",
    "    dots = np.where(x.T.flatten()==1)[0] # .T sets Fortran order down-then-right\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b+1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy2encoding_no_overlap(predicts, img_name, scores):\n",
    "    sum_predicts = np.sum(predicts, axis=2)\n",
    "    rows, cols = np.where(sum_predicts>=2)\n",
    "    \n",
    "    for i in zip(rows, cols):\n",
    "        instance_indicies = np.where(np.any(predicts[i[0],i[1],:]))[0]\n",
    "        highest = instance_indicies[0]\n",
    "        predicts[i[0],i[1],:] = predicts[i[0],i[1],:]*0\n",
    "        predicts[i[0],i[1],highest] = 1\n",
    "    \n",
    "    ImageId = []\n",
    "    EncodedPixels = []\n",
    "    print(predicts.shape)\n",
    "    for i in range(predicts.shape[2]): \n",
    "        rle = rle_encoding(predicts[:,:,i])\n",
    "        if len(rle)>0:\n",
    "            ImageId.append(img_name)\n",
    "            EncodedPixels.append(rle)    \n",
    "    return ImageId, EncodedPixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_ids = []\n",
    "rles = []\n",
    "for id, raw_pred in zip(test_ids, raw_predictions):\n",
    "    ids, rle = numpy2encoding_no_overlap(raw_pred[0], id, raw_pred[1])\n",
    "    new_test_ids += ids\n",
    "    rles += rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({ 'ImageId' : new_test_ids , 'EncodedPixels' : rles})\n",
    "df.to_csv('/output/submission.csv', index=False, columns=['ImageId', 'EncodedPixels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should get you to around 0.44 on the LB. \n",
    "\n",
    "Tweak it and improve your score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_py3",
   "language": "python",
   "name": "dl_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
